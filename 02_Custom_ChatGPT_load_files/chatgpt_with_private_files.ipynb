{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e67be67-89d8-4cf4-9a51-dfed66d63a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Arquivos\\Dev\\artificial_inteligence_ai\\langchain\\02_Custom_ChatGPT_load_files\\venv\\lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wikipedia\n",
    "from langchain.document_loaders \\\n",
    "    import PyPDFLoader, Docx2txtLoader, TextLoader, WikipediaLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone as PineconeLangChain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import ConversationalRetrievalChain, RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=False) \n",
    "\n",
    "def load_document(file):\n",
    "    name, extension = os.path.splitext(file)\n",
    "    if extension == '.pdf':\n",
    "        print(f'Loading {file}')\n",
    "        document_loader = PyPDFLoader(file)\n",
    "    elif extension == '.docx':\n",
    "        print(f'Loading {file}')\n",
    "        document_loader = Docx2txtLoader(file)\n",
    "    elif extension in ('.txt', '.py'):\n",
    "        document_loader = TextLoader(file)\n",
    "    else:\n",
    "        print('Document format is not supported!')\n",
    "        return None\n",
    "    return document_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc2ed642-ae54-44b2-9002-c201ad0bae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_wikipedia(query, lang='en', load_max_docs=2):\n",
    "    loader = WikipediaLoader(query=query, lang=lang, load_max_docs=load_max_docs)\n",
    "    data = loader.load()\n",
    "    print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9e701d5-9ac5-4fc0-af70-774607d7f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(data, chunk_size=256):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0)\n",
    "    return text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c42ca65-b26a-4a23-9d86-9367c06e508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_or_fetch_embeddings(index_name):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "    PINECONE_API_ENV = os.environ.get(\"PINECONE_ENV\")\n",
    "    print(f\"PINECONE_API_KEY={PINECONE_API_KEY}\")\n",
    "    print(f\"PINECONE_API_ENV={PINECONE_API_ENV}\")\n",
    "    pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_API_ENV)\n",
    "    #pinecone.init(api_key=os.environ.get('PINECONE_API_KEY'), environment=os.environ.get('PINECONE_ENV'))\n",
    "    if index_name in pinecone.list_indexes():\n",
    "        print(f'Index {index_name} already exists. Loading embeddings... ', end='')\n",
    "        vector_store = PineconeLangChain.from_existing_index(index_name, embeddings)\n",
    "        print('Ok')\n",
    "    else:\n",
    "        print(f'Creating index {index_name} and embeddings...', end='')\n",
    "        pinecone.create_index(index_name, dimension=1536, metric='cosine')\n",
    "        vector_store = PineconeLangChain.from_documents(chunks, embeddings, index_name=index_name)\n",
    "        print('Ok')\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2f7515a-293c-4e0e-8d6a-4b226173e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pinecone_index(index_name='all'):\n",
    "    PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "    PINECONE_API_ENV = os.environ.get(\"PINECONE_ENV\")\n",
    "    print(f\"PINECONE_API_KEY={PINECONE_API_KEY}\")\n",
    "    print(f\"PINECONE_API_ENV={PINECONE_API_ENV}\")\n",
    "    pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_API_ENV)\n",
    "    #pinecone.init(api_key=os.environ.get('PINECONE_API_KEY'), environment=os.environ.get('PINECONE_ENV'))\n",
    "    if index_name == 'all':\n",
    "        indexes = pinecone.list_indexes()\n",
    "        print('Deleting all indexes... ')\n",
    "        for index in indexes:\n",
    "            pinecone.delete_index(index)\n",
    "        print('Ok')\n",
    "    else:\n",
    "        print(f'Deleting index {index_name}...', end='')\n",
    "        pinecone.delete_index(index_name)\n",
    "        print('Ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ef11e28-495e-4998-af47-1b0979acfd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_and_get_answer(vector_store, q):\n",
    "    llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1)\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "    answer = chain.run(q)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31b8d187-d71d-4bd1-8dd6-68bbc7e4f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema import SystemMessage\n",
    "\n",
    "\"\"\"\n",
    "chat_memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history',\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "chatbot_prompt = ChatPromptTemplate(\n",
    "    input_variables=[\"content\", \"chat_history\"],\n",
    "    messages=[\n",
    "        SystemMessage(content=\"You are a chatbot having a conversation with a human.\"),\n",
    "        MessagesPlaceholder(variable_name=\"chatbot_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=1)\n",
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "crc = ConversationalRetrievalChain.from_llm(llm, retriever, memory=chat_memory)\n",
    "\n",
    "def ask_with_memory(vector_store, question, chat_history, crc):\n",
    "    result = crc({'question': question, 'chat_history': chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    return result, chat_history\n",
    "\"\"\"\n",
    "\n",
    "def ask_with_memory(vector_store, question, chat_history=[]):\n",
    "    from langchain.chains import ConversationalRetrievalChain\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "    \n",
    "    llm = ChatOpenAI(temperature=1)\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "    \n",
    "    crc = ConversationalRetrievalChain.from_llm(llm, retriever)\n",
    "    result = crc({'question': question, 'chat_history': chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    \n",
    "    return result, chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2c4f80-49f9-4157-8be2-925b5db93ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write Quit or Exit to quit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Write 1 for a document or 2 for Wikipedia 1\n",
      "Share the path of the document C:\\Users\\claud\\Downloads\\PythonWebDeveloper.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading C:\\Users\\claud\\Downloads\\PythonWebDeveloper.pdf\n",
      "PINECONE_API_KEY=762ffcc0-59de-4084-8e83-1ef0ebf15c8b\n",
      "PINECONE_API_ENV=gcp-starter\n",
      "Deleting all indexes... \n",
      "Ok\n",
      "PINECONE_API_KEY=762ffcc0-59de-4084-8e83-1ef0ebf15c8b\n",
      "PINECONE_API_ENV=gcp-starter\n",
      "Creating index chatgpt and embeddings...Ok\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question #1 What are the main requirements of this job description?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main requirements for this job description include:\n",
      "- Advanced skills in Python programming language.\n",
      "- Experience in developing and maintaining web applications.\n",
      "- Proficiency in implementing microservices and applying domain-driven design principles.\n",
      "- Familiarity with RESTful API architecture pattern.\n",
      "- Strong command of Python and web development frameworks.\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question #2 What was my last question?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desculpe, mas eu não consigo acessar o histórico de perguntas anteriores.\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question #3 print(chat_history)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desculpe, mas não tenho acesso ao histórico das perguntas anteriores. Portanto, não consigo responder à sua pergunta sobre qual foi a sua última pergunta.\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "chat_history = []\n",
    "chatbot_mode = \"initial\"\n",
    "print(\"Write Quit or Exit to quit\")\n",
    "while True:\n",
    "    if chatbot_mode == \"initial\":\n",
    "        q = input(\"Write 1 for a document or 2 for Wikipedia\")\n",
    "        if q == \"1\":\n",
    "            q = input(\"Share the path of the document\")\n",
    "            chatbot_mode = \"document\"\n",
    "        elif q == \"2\":\n",
    "            q = input(\"Share the Wikipedia query\")\n",
    "            chatbot_mode = \"wikipedia\"\n",
    "        elif q.lower() in [\"quit\",\"exit\"]:\n",
    "            print(\"See you soon!\")\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "        if chatbot_mode == \"document\":\n",
    "            data = load_document(q)\n",
    "            chatbot_mode = \"process\"\n",
    "        elif chatbot_mode == \"wikipedia\":\n",
    "            data = load_from_wikipedia(q)\n",
    "            chatbot_mode = \"process\"\n",
    "        else:\n",
    "            continue\n",
    "        if data is not None and chatbot_mode == \"process\":\n",
    "            delete_pinecone_index()\n",
    "            chunks = chunk_data(data)\n",
    "            index_name = 'chatgpt'\n",
    "            vector_store = insert_or_fetch_embeddings(index_name)\n",
    "            chatbot_mode = \"question\"\n",
    "            i = 1\n",
    "    if chatbot_mode == \"question\":\n",
    "        q = input(f\"Question #{i}\")\n",
    "        i = i + 1\n",
    "    if q.lower() in [\"quit\",\"exit\"]:\n",
    "        print(\"See you soon!\")\n",
    "        break\n",
    "    elif chatbot_mode == \"question\":\n",
    "        result, chat_history = ask_with_memory(vector_store, q, chat_history)\n",
    "        print (result['answer'])\n",
    "        print(\"----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9bb167-1012-4817-a722-7081514a3510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
